\section{Introduction}

\paragraph{Illustrating example of ITMs}
The following example illustrates several common idioms of programming with ITMs:

\begin{quote}
    The Interactive Turing Machine $M$ is parameterized by a machine $M'$. First we run two instances of $M'$, called $M'_0$ and $M'_1$, in a sandbox. The randomness tape of the two instances is tee’d, so that each machine draws exactly the same random bits. The subroutine input tape of F is multiplexed… incoming messages of the form $(b, m)$ result in sending message $m$ to the subroutine tape of instance $M_b$. If either sandbox instance writes a message to its subroutine output tape, this is forwarded to $M$'s subroutine output tape directly.
\end{quote}

    The most important composition operation is “sandboxed execution” --- where one machine, the host, executes an instance of another machine, the guest. The host has complete control of the guest’s I/O, i.e., it is able to inject and intercept messages involving those tapes, typically adding or removing layers of “routing” metadata and forwarding the messages along its other tapes. Interacting over tapes is the *only* way the host interacts with the guest --- machine composition is typically “black box”, as it’s not usually necessary to perform deep analysis of the guest’s code.

    There’s a distinction between a machine (which is like a program) and an instance (which is like a running process).

 It also doesn’t make sense for a machine to send a tape along a tape (the way channels are typically passed along channels in Pi calculus) -- tapes and the data that can be written on tapes are of different sorts.

It would seem that running these two instances, $M'_0$ and $M'_1$, concurrently, may lead to race conditions. However, this is not the case --- the semantics of Interactive Turing Machines is deterministic, even for running programs. (Even random tapes are treated explicitly, achieve a probabilistic semantics only at the very end quantifying the uniform dist
ribution of values on those tapes).

\paragraph{Constraints}
Our language is based on the following design constraints:
\begin{enumerate}
\item Each channel can only be “read” by a unique process. This is enforced by our effect system, which keeps track of “read sets”, and guarantees that each message can be handled by a unique process.
\item Only the active process in a system can “write”... after writing, it must again become passive, only reactivated when it receives a message. Our effect system keeps track of whether a process is active $(W; R)$ or passive $(R)$.
\item Channels are opaque -- they can be stored in data structures and reference cells, but can not be sent along other channels or converted to strings.
\end{enumerate}



Encoding of $F$ in \lang
\begin{figure*}
\begin{lstlisting} 
def F (M : () @ R) :=
  nu inL inR randL randR. 
  teeRandom rand randL randR
  | M[ in: inL, rand:randL ]
  | M[ in: inR, rand:randR ]
  | !{ (b, m) <-- rd in;
      m --> (inL,inR)[b] }

def teeRandom (getRand, rand) (getRandL, randL) (getRandR, randR) :=
  let bits := newRef []
  | stream getRandL randL
  | stream getRandR randR
     where
        stream (getRand', rand') :=
        let counter := newRef 0
        !{ () <-- getRand';
           if @counter < len (@bits):
             @bits[@counter] --> rand'
                counter++
           else
              () <-- getRand; 
              b --> rand
              bits[@counter] := b
              counter++
              b --> rand'
         }
\end{lstlisting}
\end{figure*}





\subsection{Why bother with Simulation Based Security? Isn't this out of place?}
Simulation-based security notions are stronger than property-based definitions, because they guarantee security when concurrent composition with instances other arbitrary protocols.
Additionally, a virtue of simulation-based specifications is that they consist of executable code and are, in our subjective opinion, often easier to understand and work with.

It is actually because of the diversity and complexity of the cryptocurrency applications that motivate our work (many of which rely on cryptography) that we consider the discipline of composable simulation-based security an essential goal.

Our contribution is a simulation-based security framework for asynchronous protocols that corrects flaws in earlier attempts. We affirm that the BFT protocols we study are still secure in this stronger model. This ensures that these protocols can be used as components of larger (e.g., cryptocurrencies) simulation-based applications.

We stress that the protocols we examine in this paper are not new, and have already been proven correct in traditional asynchronous models.
That they are also secure in our simulation-based framework model is not surprising, but rather serves as a useful sanity check of our model.

Actually the proofs carry over in tact, and the simulators are simple, since the protocols have little to ``hide.''

Although we present the protocols and specifications in the style of our new formalism, it is not necessary to understand the intricate details of our model to read.
Instead these can be read as pseudocode, and intuitions from the standard informal asynchronous model remains applicable.

